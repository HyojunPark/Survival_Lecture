[["index.html", "SOC6280: Survival Analysis: Practice Chapter 1 About", " SOC6280: Survival Analysis: Practice Hyojun Park 2023-03-15 Chapter 1 About This is an additional lecture notes for Survival Analysis course. "],["bias-assessment.html", "Chapter 2 Bias assessment 2.1 Bias due to omitted confounders 2.2 Overadjustment bias 2.3 Total effect 2.4 Overadjustment 2.5 Logistic models", " Chapter 2 Bias assessment Available at https://rpubs.com/Hyojun/bias 2.1 Bias due to omitted confounders \\[y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_2 + \\dots + \\epsilon_i; \\;\\; for \\;\\; i=1, \\dots, n\\] where the errors \\(\\epsilon_i \\sim N(0, \\sigma^2)\\) with independent and identically distributed (i.i.d.) Let’s assume the following association is true (i.e., gold standard) without any selection bias, measurement bias, and other unmeasured confoundings. N &lt;- 100000 C &lt;- rnorm(N) X &lt;- .5 * C + rnorm(N) Y &lt;- .3 * C + .4 * X + rnorm(N) 2.1.1 Gold standard With the correct model specification (i.e., \\(C\\) as a confounder), we get an unbiased estimate of \\(X\\) on \\(Y\\). # Gold standard glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.3913 -0.6740 0.0017 0.6729 4.5984 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.002618 0.003155 -0.83 0.407 ## X 0.401592 0.003158 127.18 &lt;2e-16 *** ## C 0.298346 0.003526 84.60 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.9953407) ## ## Null deviance: 140736 on 99999 degrees of freedom ## Residual deviance: 99531 on 99997 degrees of freedom ## AIC: 283326 ## ## Number of Fisher Scoring iterations: 2 2.1.2 Misspecified model: a confounder, \\(C\\), was omitted from the model By omitting \\(C\\), the estimate of \\(X\\) was biased either “away from” or “towards to” the null # C was omitted glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.7547 -0.7009 0.0010 0.6986 4.5059 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.002099 0.003266 -0.643 0.52 ## X 0.521810 0.002919 178.757 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.066573) ## ## Null deviance: 140736 on 99999 degrees of freedom ## Residual deviance: 106655 on 99998 degrees of freedom ## AIC: 290237 ## ## Number of Fisher Scoring iterations: 2 2.1.3 Bias “away from” or “towards to” the null? N &lt;- 100000 C &lt;- rnorm(N) X &lt;- -.5 * C + rnorm(N) Y &lt;- -.3 * C + .4 * X + rnorm(N) # C was omitted glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.2198 -0.6817 0.0005 0.6768 4.2460 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.004496 0.003167 -1.42 0.156 ## X 0.403438 0.003168 127.35 &lt;2e-16 *** ## C -0.297215 0.003529 -84.22 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.002803) ## ## Null deviance: 141235 on 99999 degrees of freedom ## Residual deviance: 100277 on 99997 degrees of freedom ## AIC: 284073 ## ## Number of Fisher Scoring iterations: 2 glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.3327 -0.7020 -0.0003 0.6974 4.4609 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.004441 0.003277 -1.355 0.175 ## X 0.521703 0.002939 177.523 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.07393) ## ## Null deviance: 141235 on 99999 degrees of freedom ## Residual deviance: 107391 on 99998 degrees of freedom ## AIC: 290924 ## ## Number of Fisher Scoring iterations: 2 2.1.4 A \\(C\\) is not a confounder on \\(X\\) and \\(Y\\) N &lt;- 100000 C &lt;- rnorm(N) X &lt;- rnorm(N) Y &lt;- .4 * X + rnorm(N) 2.1.5 Correct model specification: Without \\(C\\) glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.1421 -0.6714 -0.0002 0.6690 4.2192 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.0009383 0.0031535 -0.298 0.766 ## X 0.3924725 0.0031445 124.814 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.9944728) ## ## Null deviance: 114938 on 99999 degrees of freedom ## Residual deviance: 99445 on 99998 degrees of freedom ## AIC: 283237 ## ## Number of Fisher Scoring iterations: 2 2.1.6 Misspecified model with \\(C\\) glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.1400 -0.6714 0.0001 0.6688 4.2218 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.000938 0.003154 -0.297 0.766 ## X 0.392446 0.003145 124.800 &lt;2e-16 *** ## C -0.002999 0.003159 -0.949 0.342 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.9944738) ## ## Null deviance: 114938 on 99999 degrees of freedom ## Residual deviance: 99444 on 99997 degrees of freedom ## AIC: 283239 ## ## Number of Fisher Scoring iterations: 2 2.1.7 A \\(C\\) is a colloder on \\(X\\) and \\(Y\\) N &lt;- 100000 X &lt;- rnorm(N) Y &lt;- .7 * X + rnorm(N) C &lt;- 1.2 * X + .6 * Y + rnorm(N) 2.1.8 Correct model specification: Without \\(C\\) glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.5592 -0.6752 -0.0002 0.6735 4.7663 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.003792 0.003166 -1.198 0.231 ## X 0.701010 0.003156 222.124 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.002096) ## ## Null deviance: 149650 on 99999 degrees of freedom ## Residual deviance: 100208 on 99998 degrees of freedom ## AIC: 284001 ## ## Number of Fisher Scoring iterations: 2 2.1.9 Misspecified model with \\(C\\) This is one of examples of selection bias. For example, let’s say, \\(X\\) is Education, \\(Y\\) is income, and \\(C\\) is social welfare program. People at lower education (i.e., high risk group in terms of exposure) and lower income (i.e., higher risk group in terms of outcome) are more likely to register social welfare program. If survey was conducted based on the registered social welfare program, the “estimated” association from this “disproportionally selected” respondents are likely biased. glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -3.6964 -0.5801 0.0000 0.5778 3.6577 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.002126 0.002708 -0.785 0.432 ## X -0.020419 0.004633 -4.407 1.05e-05 *** ## C 0.443912 0.002317 191.574 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.7330606) ## ## Null deviance: 149650 on 99999 degrees of freedom ## Residual deviance: 73304 on 99997 degrees of freedom ## AIC: 252740 ## ## Number of Fisher Scoring iterations: 2 2.2 Overadjustment bias Please note that this is not a comprehensive example; only reflect one aspect of potential overadjustement bias. Let’s assume a model with \\(M\\) as a mediator. N &lt;- 100000 X &lt;- rnorm(N) M &lt;- .5 * X + rnorm(N) Y &lt;- .3 * X + .4 * M + rnorm(N) 2.3 Total effect glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.6920 -0.7238 0.0051 0.7266 4.6174 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.001431 0.003400 0.421 0.674 ## X 0.499182 0.003387 147.402 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.156214) ## ## Null deviance: 140741 on 99999 degrees of freedom ## Residual deviance: 115619 on 99998 degrees of freedom ## AIC: 298307 ## ## Number of Fisher Scoring iterations: 2 2.4 Overadjustment glm.unbiased &lt;- glm(Y~X + M, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + M, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.4095 -0.6765 0.0006 0.6723 4.3489 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.003517 0.003157 1.114 0.265 ## X 0.301734 0.003509 85.991 &lt;2e-16 *** ## M 0.399822 0.003156 126.674 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.9963448) ## ## Null deviance: 140741 on 99999 degrees of freedom ## Residual deviance: 99631 on 99997 degrees of freedom ## AIC: 283427 ## ## Number of Fisher Scoring iterations: 2 2.5 Logistic models 2.5.1 Sex as a Confounder, \\(C\\) MYY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 5 ) MYN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 8 ) MNY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 45 ) MNN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 72 ) FYY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 25 ) FYN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 10 ) FNY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 25 ) FNN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 10 ) Ex_confounder &lt;- rbind(MYY, MYN, MNY, MNN, FYY, FYN, FNY, FNN) Convert Freq table to raw data library(tidyr) raw_confounder &lt;- Ex_confounder %&gt;% uncount(freq) glm.unbiased &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_confounder) summary(glm.unbiased) ## ## Call: ## glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.40059 -1.11100 -0.07073 1.24530 1.24530 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.1582 0.1627 -0.972 0.3309 ## SmokingYes 0.6690 0.3397 1.970 0.0489 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 277.26 on 199 degrees of freedom ## Residual deviance: 273.28 on 198 degrees of freedom ## AIC: 277.28 ## ## Number of Fisher Scoring iterations: 4 Full model: glm_logit &lt;- glm(Cancer ~ Smoking + Sex , family=binomial(link = &quot;logit&quot;), data=raw_confounder) glm_logit ## ## Call: glm(formula = Cancer ~ Smoking + Sex, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder) ## ## Coefficients: ## (Intercept) SmokingYes SexMale ## 9.163e-01 4.266e-15 -1.386e+00 ## ## Degrees of Freedom: 199 Total (i.e. Null); 197 Residual ## Null Deviance: 277.3 ## Residual Deviance: 257 AIC: 263 Stratified models ## For males raw_confounder_M &lt;- raw_confounder[ which(raw_confounder$Sex==&#39;Male&#39;), ] glm_logit_m &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_confounder_M) glm_logit_m ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder_M) ## ## Coefficients: ## (Intercept) SmokingYes ## -4.700e-01 6.672e-16 ## ## Degrees of Freedom: 129 Total (i.e. Null); 128 Residual ## Null Deviance: 173.2 ## Residual Deviance: 173.2 AIC: 177.2 # For females raw_confounder_F &lt;- raw_confounder[ which(raw_confounder$Sex==&#39;Female&#39;), ] glm_logit_f &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_confounder_F) glm_logit_f ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder_F) ## ## Coefficients: ## (Intercept) SmokingYes ## 9.163e-01 9.400e-16 ## ## Degrees of Freedom: 69 Total (i.e. Null); 68 Residual ## Null Deviance: 83.76 ## Residual Deviance: 83.76 AIC: 87.76 2.5.2 Sex as a Moderator, \\(M\\) MYY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 5 ) MYN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 4 ) MNY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 45 ) MNN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 68 ) FYY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 25 ) FYN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 14 ) FNY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 25 ) FNN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 14 ) Ex_moderator &lt;- rbind(MYY, MYN, MNY, MNN, FYY, FYN, FNY, FNN) Convert Freq table to raw data library(tidyr) raw_moderator &lt;- Ex_moderator %&gt;% uncount(freq) Full model: glm_logit &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_moderator) glm_logit ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_moderator) ## ## Coefficients: ## (Intercept) SmokingYes ## -0.1582 0.6690 ## ## Degrees of Freedom: 199 Total (i.e. Null); 198 Residual ## Null Deviance: 277.3 ## Residual Deviance: 273.3 AIC: 277.3 Stratified models ## For males raw_moderator_M &lt;- raw_moderator[ which(raw_moderator$Sex==&#39;Male&#39;), ] glm_logit_m &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_moderator_M) glm_logit_m ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_moderator_M) ## ## Coefficients: ## (Intercept) SmokingYes ## -0.4128 0.6360 ## ## Degrees of Freedom: 121 Total (i.e. Null); 120 Residual ## Null Deviance: 165.1 ## Residual Deviance: 164.3 AIC: 168.3 # For females raw_moderator_F &lt;- raw_moderator[ which(raw_moderator$Sex==&#39;Female&#39;), ] glm_logit_f &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_moderator_F) glm_logit_f ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_moderator_F) ## ## Coefficients: ## (Intercept) SmokingYes ## 5.798e-01 -2.621e-16 ## ## Degrees of Freedom: 77 Total (i.e. Null); 76 Residual ## Null Deviance: 101.8 ## Residual Deviance: 101.8 AIC: 105.8 "],["survival-analyses-introduction.html", "Chapter 3 Survival Analyses: Introduction 3.1 Set packages and library 3.2 dataset 3.3 Nonparametric estimation 3.4 Proportional Hazards and Cox Regression 3.5 Parametric estimation", " Chapter 3 Survival Analyses: Introduction 3.1 Set packages and library library(eha) library(survival) #install.packages(&quot;ggfortify&quot;) library(ggfortify) ## Loading required package: ggplot2 library(ggplot2) library(tidyverse) ## ── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.0 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ lubridate 1.9.2 ✔ tibble 3.2.0 ## ✔ purrr 1.0.1 ## ── Conflicts ──────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the ]8;;http://conflicted.r-lib.org/conflicted package]8;; to force all conflicts to become errors library(data.table) ## ## Attaching package: &#39;data.table&#39; ## ## The following objects are masked from &#39;package:lubridate&#39;: ## ## hour, isoweek, mday, minute, month, quarter, second, wday, week, ## yday, year ## ## The following objects are masked from &#39;package:dplyr&#39;: ## ## between, first, last ## ## The following object is masked from &#39;package:purrr&#39;: ## ## transpose #install.packages(&quot;flextable&quot;) library(flextable) ## ## Attaching package: &#39;flextable&#39; ## ## The following object is masked from &#39;package:purrr&#39;: ## ## compose library(knitr) 3.2 dataset The child dataset in eha package summary(child) # descriptive statistics ## id m.id sex socBranch ## Min. : 9 Min. : 55 male :13676 official: 610 ## 1st Qu.:249504 1st Qu.:248826 female:12898 farming :18641 ## Median :500126 Median :504920 business: 318 ## Mean :500080 Mean :501874 worker : 7005 ## 3rd Qu.:750266 3rd Qu.:752827 ## Max. :999976 Max. :999932 ## birthdate enter exit event illeg ## Min. :1850-01-01 Min. :0 Min. : 0.003 Min. :0.0000 no :24567 ## 1st Qu.:1861-01-05 1st Qu.:0 1st Qu.:15.000 1st Qu.:0.0000 yes: 2007 ## Median :1870-08-08 Median :0 Median :15.000 Median :0.0000 ## Mean :1869-06-09 Mean :0 Mean :12.231 Mean :0.2113 ## 3rd Qu.:1878-05-08 3rd Qu.:0 3rd Qu.:15.000 3rd Qu.:0.0000 ## Max. :1884-12-31 Max. :0 Max. :15.000 Max. :1.0000 ## m.age ## Min. :15.83 ## 1st Qu.:27.18 ## Median :31.79 ## Mean :32.03 ## 3rd Qu.:36.74 ## Max. :50.86 str(child) # structure ## &#39;data.frame&#39;: 26574 obs. of 10 variables: ## $ id : int 9 150 158 178 263 342 363 393 408 486 ... ## $ m.id : int 246606 377744 118277 715337 978617 282943 341341 840879 586140 564736 ... ## $ sex : Factor w/ 2 levels &quot;male&quot;,&quot;female&quot;: 1 1 1 1 2 1 1 1 2 2 ... ## $ socBranch: Factor w/ 4 levels &quot;official&quot;,&quot;farming&quot;,..: 2 2 4 2 4 2 2 2 2 2 ... ## $ birthdate: Date, format: &quot;1853-05-23&quot; &quot;1853-07-19&quot; ... ## $ enter : num 0 0 0 0 0 0 0 0 0 0 ... ## $ exit : num 15 15 15 15 0.559 0.315 15 15 15 15 ... ## $ event : num 0 0 0 0 1 1 0 0 0 0 ... ## $ illeg : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 2 ... ## $ m.age : num 35 30.6 29.3 41.2 42.1 ... head(child) # preview ## id m.id sex socBranch birthdate enter exit event illeg m.age ## 3 9 246606 male farming 1853-05-23 0 15.000 0 no 35.009 ## 42 150 377744 male farming 1853-07-19 0 15.000 0 no 30.609 ## 47 158 118277 male worker 1861-11-17 0 15.000 0 no 29.320 ## 54 178 715337 male farming 1872-11-16 0 15.000 0 no 41.183 ## 78 263 978617 female worker 1855-07-19 0 0.559 1 no 42.138 ## 102 342 282943 male farming 1855-09-29 0 0.315 1 no 32.931 3.3 Nonparametric estimation 3.3.1 Data for nonparametric models The following code creates a set of vector for survival analysis. It contains 5 individuals’ survival time. \\(1\\) is an event (i.e., failure, death) and \\(0\\) is a cencored case. tt &lt;- c(7,6,6,5,2,4) cens &lt;- c(0,1,0,0,1,1) Surv(tt,cens) ## [1] 7+ 6 6+ 5+ 2 4 aaa &lt;- Surv(tt,cens) # demonstration only for checking how survival dataset was constructed aaa ## [1] 7+ 6 6+ 5+ 2 4 3.3.2 Kaplan-Meier estimator ## Models result.km &lt;- survfit(Surv(tt,cens)~1, conf.type=&quot;log-log&quot;) ## Table result.km ## Call: survfit(formula = Surv(tt, cens) ~ 1, conf.type = &quot;log-log&quot;) ## ## n events median 0.95LCL 0.95UCL ## [1,] 6 3 6 2 NA summary(result.km) ## Call: survfit(formula = Surv(tt, cens) ~ 1, conf.type = &quot;log-log&quot;) ## ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 2 6 1 0.833 0.152 0.2731 0.975 ## 4 5 1 0.667 0.192 0.1946 0.904 ## 6 3 1 0.444 0.222 0.0662 0.785 ## Plots par(mfrow = c(1, 2))# Two panels, &quot;one row, two columns&quot;. plot(result.km, ylab = &quot;Survival probability&quot;, xlab = &quot;Time&quot;, mark.time = T, main=&quot;KM survival curve&quot;) abline(h = 0.5, col = &quot;sienna&quot;, lty = 3) plot(result.km, ylab = &quot;Cumulative hazard&quot;, xlab = &quot;Time&quot;, mark.time = T, fun=&quot;cumhaz&quot;, main=&quot;KM cumulative hazard curve&quot;) abline(h = 0.5, col = &quot;sienna&quot;, lty = 3) 3.3.3 Nelson-Aalen estimator ## Models result.fh &lt;- survfit(Surv(tt,cens)~1, conf.type=&quot;log-log&quot;, type=&quot;fh&quot;) ## Table result.fh ## Call: survfit(formula = Surv(tt, cens) ~ 1, conf.type = &quot;log-log&quot;, ## type = &quot;fh&quot;) ## ## n events median 0.95LCL 0.95UCL ## [1,] 6 3 6 2 NA summary(result.fh) ## Call: survfit(formula = Surv(tt, cens) ~ 1, conf.type = &quot;log-log&quot;, ## type = &quot;fh&quot;) ## ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 2 6 1 0.846 0.141 0.306 0.977 ## 4 5 1 0.693 0.180 0.229 0.913 ## 6 3 1 0.497 0.210 0.101 0.807 # Plots par(mfrow = c(1, 2))# Two panels, &quot;one row, two columns&quot;. plot(result.fh, ylab = &quot;Survival probability&quot;, xlab = &quot;Time&quot;, mark.time = T, main=&quot;NA survival curve&quot;) abline(h = 0.5, col = &quot;sienna&quot;, lty = 3) plot(result.fh, ylab = &quot;Cumulative hazard&quot;, xlab = &quot;Time&quot;, mark.time = T, fun=&quot;cumhaz&quot;, main=&quot;NA cumulative hazard curve&quot;) abline(h = 0.5, col = &quot;sienna&quot;, lty = 3) 3.3.4 Comparisons by groups bysex &lt;- survfit(Surv(enter, exit, event) ~ sex, data=child, conf.type=&quot;log-log&quot;) ## Tables #bysex #summary(bysex) summary(bysex, times=c(0, 3, 6, 9, 12, 15)) # add time points ## Call: survfit(formula = Surv(enter, exit, event) ~ sex, data = child, ## conf.type = &quot;log-log&quot;) ## ## sex=male ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 0 13676 0 1.000 0.00000 1.000 1.000 ## 3 11614 1924 0.859 0.00298 0.853 0.865 ## 6 10955 555 0.818 0.00331 0.811 0.824 ## 9 10653 240 0.800 0.00344 0.793 0.806 ## 12 10452 146 0.789 0.00351 0.782 0.795 ## 15 10269 120 0.780 0.00356 0.773 0.786 ## ## sex=female ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 0 12898 0 1.000 0.00000 1.000 1.000 ## 3 11152 1611 0.875 0.00292 0.869 0.880 ## 6 10578 501 0.835 0.00328 0.829 0.842 ## 9 10262 242 0.816 0.00343 0.809 0.823 ## 12 10079 129 0.806 0.00350 0.799 0.813 ## 15 9872 148 0.794 0.00358 0.787 0.801 ## plots plot(bysex, ylab = &quot;Survival probabilities&quot;, xlab = &quot;Survival time&quot;, #mark.time = T, main=&quot;Kaplan-Meier survival curve estimate with 95% CIs&quot; ) legend(&quot;topright&quot;, c(&quot;Male&quot;,&quot;Female&quot;), lty=c(&quot;solid&quot;,&quot;dashed&quot;), col=c(&quot;black&quot;,&quot;red&quot;)) 3.3.5 Better KM figures library(ggfortify) library(ggplot2) autoplot(bysex, ylab = &quot;Survival probabilities&quot;, xlab = &quot;Survival time&quot;, #mark.time = T, main=&quot;Kaplan-Meier survival curve estimate with 95% CIs&quot; ) 3.3.6 Nonparametric models using a \\(child\\) dataset from eha ## Plots par(mfrow = c(1, 2))# Two panels, &quot;one row, two columns&quot;. with(child, plot(Surv(enter, exit, event), fun = &quot;cumhaz&quot;, main = &quot;Cumulativa hazards function&quot;, xlab = &quot;Duration&quot;)) with(child, plot(Surv(enter, exit, event), main = &quot;Survival function&quot;, xlab = &quot;Duration&quot;)) 3.4 Proportional Hazards and Cox Regression cox01 &lt;- coxreg(Surv(enter, exit, event) ~ sex + socBranch + birthdate, data = child) print(summary(cox01), digits = 4) ## Covariate Mean Coef Rel.Risk S.E. LR p ## sex 0.0019 ## male 0.510 0 1 (reference) ## female 0.490 -0.083 0.920 0.027 ## socBranch 0.0001 ## official 0.021 0 1 (reference) ## farming 0.710 -0.017 0.983 0.092 ## business 0.011 0.330 1.391 0.141 ## worker 0.258 0.099 1.104 0.094 ## birthdate 1869-07-13 -0.000 1.000 0.000 0.0000 ## ## Events 5616 ## Total time at risk 325030 ## Max. log. likelihood -56481 ## LR test statistic 67.10 ## Degrees of freedom 5 ## Overall p-value 4.11227e-13 child$cohort &lt;- floor(toTime(child$birthdate)) # age cohort cox02 &lt;- coxreg(Surv(enter, exit, event) ~ sex + socBranch + cohort, data = child) print(summary(cox02), digits = 4) ## Covariate Mean Coef Rel.Risk S.E. LR p ## sex 0.0018 ## male 0.510 0 1 (reference) ## female 0.490 -0.083 0.920 0.027 ## socBranch 0.0001 ## official 0.021 0 1 (reference) ## farming 0.710 -0.017 0.984 0.092 ## business 0.011 0.330 1.390 0.141 ## worker 0.258 0.099 1.104 0.094 ## cohort 1869.035 -0.008 0.992 0.001 0.0000 ## ## Events 5616 ## Total time at risk 325030 ## Max. log. likelihood -56481 ## LR test statistic 66.79 ## Degrees of freedom 5 ## Overall p-value 4.75731e-13 range(child$cohort) ## [1] 1850 1884 child$cohort &lt;- child$cohort - 1860 cox03 &lt;- coxreg(Surv(enter, exit, event) ~ sex + socBranch + cohort, data = child) # Table summary(cox03) ## Covariate Mean Coef Rel.Risk S.E. LR p ## sex 0.002 ## male 0.510 0 1 (reference) ## female 0.490 -0.083 0.920 0.027 ## socBranch 0.000 ## official 0.021 0 1 (reference) ## farming 0.710 -0.017 0.984 0.092 ## business 0.011 0.330 1.390 0.141 ## worker 0.258 0.099 1.104 0.094 ## cohort 9.035 -0.008 0.992 0.001 0.000 ## ## Events 5616 ## Total time at risk 325030 ## Max. log. likelihood -56481 ## LR test statistic 66.79 ## Degrees of freedom 5 ## Overall p-value 4.75731e-13 # Plots par(mfrow = c(1, 2), las = 1) plot(cox03, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(cox03, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) 3.4.1 A visual check for a proportionality assumption library(survival) ## Create survival vector for fish dataset child$SurvObj &lt;- with(child, Surv(enter, exit, event)) par(mfrow = c(1, 2), las = 1) plot(survfit(SurvObj ~ sex, data=child), main = &quot;Proportional hazard by sex&quot;, ylab = &quot;Survival&quot;, col=c(&quot;black&quot;, &quot;red&quot;) ) plot(survfit(SurvObj ~ sex, data=child), fun = &quot;cloglog&quot;, ylab = &quot;Log-log survival&quot;, main = &quot;Proportional hazard by sex&quot;, col=c(&quot;black&quot;, &quot;red&quot;) ) library(survival) ## Create survival vector for fish dataset child$SurvObj &lt;- with(child, Surv(enter, exit, event)) par(mfrow = c(1, 2), las = 1) plot(survfit(SurvObj ~ socBranch, data=child), main = &quot;Proportional hazard by sex&quot;, ylab = &quot;Survival&quot;, col=c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;) ) plot(survfit(SurvObj ~ socBranch, data=child), fun = &quot;cloglog&quot;, ylab = &quot;Log-log survival&quot;, main = &quot;Proportional hazard by sex&quot;, col=c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;) ) 3.5 Parametric estimation 3.5.1 Weibull model # Models parm_weib &lt;- phreg(Surv(enter, exit, event) ~ sex + socBranch + cohort , dist = &quot;weibull&quot;, data = child) # Table #print(summary(parm), digits = 4) parm_weib ## Call: ## phreg(formula = Surv(enter, exit, event) ~ sex + socBranch + ## cohort, data = child, dist = &quot;weibull&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## sex ## male 0.510 0 1 (reference) ## female 0.490 -0.083 0.920 0.027 0.002 ## socBranch ## official 0.021 0 1 (reference) ## farming 0.710 -0.026 0.975 0.092 0.780 ## business 0.011 0.332 1.393 0.141 0.019 ## worker 0.258 0.092 1.097 0.094 0.329 ## cohort 9.035 -0.008 0.992 0.001 0.000 ## ## log(scale) 5.887 0.228 0.000 ## log(shape) -0.880 0.013 0.000 ## ## Events 5616 ## Total time at risk 325030 ## Max. log. likelihood -25131 ## LR test statistic 68.69 ## Degrees of freedom 5 ## Overall p-value 1.91736e-13 # Plots par(mfrow = c(1, 2), las = 1) plot(parm_weib, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(parm_weib, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Survival&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) 3.5.2 Gompertz model # Models parm_gomp &lt;- phreg(Surv(enter, exit, event) ~ sex + socBranch + cohort , dist = &quot;gompertz&quot;, data = child) # Table #print(summary(parm), digits = 4) parm_gomp ## Call: ## phreg(formula = Surv(enter, exit, event) ~ sex + socBranch + ## cohort, data = child, dist = &quot;gompertz&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## sex ## male 0.510 0 1 (reference) ## female 0.490 -0.087 0.916 NA NA ## socBranch ## official 0.021 0 1 (reference) ## farming 0.710 -0.064 0.938 NA NA ## business 0.011 0.349 1.417 NA NA ## worker 0.258 0.066 1.068 NA NA ## cohort 9.035 -0.008 0.992 NA NA ## ## log(scale) 401.049 NA NA ## log(shape) 397.124 NA NA ## ## Events 5616 ## Total time at risk 325030 ## Max. log. likelihood -28368 ## LR test statistic 78.89 ## Degrees of freedom 5 ## Overall p-value 1.44329e-15 # Plots par(mfrow = c(1, 2), las = 1) plot(parm_gomp, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(parm_gomp, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Survival&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) "],["counting-process.html", "Chapter 4 Counting Process 4.1 Set packages and library 4.2 Example 4.3 Practice: AddHealth Public datasets", " Chapter 4 Counting Process In this section, we will cover 1) survival data structure (i.e., counting process) and 2) modeling survival data. 4.1 Set packages and library library(eha) library(survival) #install.packages(&quot;ggfortify&quot;) library(ggfortify) library(ggplot2) library(tidyverse) library(data.table) #install.packages(&quot;flextable&quot;) library(flextable) library(knitr) 4.2 Example “The oldmort dataset in eha package contains life histories of people followed from their 60th birthday to their 100th, or until death, born between June 28, 1765 and December 31, 1820 in Skellefteå. The variable enter is age at start of the given interval, exit contains the age at the end of the interval. We need to calculate follow-up time since age 60 - 60 is subtracted from enter and exit. The variable event is an indicator of death at the duration given by exit.” https://www.rdocumentation.org/packages/eha/versions/2.8.5/topics/oldmort [Göran Broström, http://ehar.se/r/ehar2/parametric.html] Here are the summary of the oldmort dataset. library(eha) oldmort01 &lt;- oldmort summary(oldmort01) # descriptive statistics ## id enter exit event ## Min. :765000603 Min. :60.00 Min. : 60.00 Mode :logical ## 1st Qu.:797001170 1st Qu.:60.00 1st Qu.: 63.88 FALSE:4524 ## Median :804001545 Median :60.07 Median : 68.51 TRUE :1971 ## Mean :803652514 Mean :64.07 Mean : 69.89 ## 3rd Qu.:812001564 3rd Qu.:66.88 3rd Qu.: 74.73 ## Max. :826002672 Max. :94.51 Max. :100.00 ## ## birthdate m.id f.id sex ## Min. :1765 Min. : 6039 Min. : 2458 male :2884 ## 1st Qu.:1797 1st Qu.:766000610 1st Qu.:763000610 female:3611 ## Median :1805 Median :775000742 Median :772000649 ## Mean :1804 Mean :771271398 Mean :762726961 ## 3rd Qu.:1812 3rd Qu.:783000743 3rd Qu.:780001077 ## Max. :1820 Max. :802000669 Max. :797001468 ## NA&#39;s :3155 NA&#39;s :3310 ## civ ses.50 birthplace imr.birth region ## unmarried: 557 middle : 233 parish:3598 Min. : 4.348 town : 657 ## married :3638 unknown:2565 region:1503 1st Qu.:12.709 industry:2214 ## widow :2300 upper : 55 remote:1394 Median :14.234 rural :3624 ## farmer :1562 Mean :15.209 ## lower :2080 3rd Qu.:17.718 ## Max. :31.967 ## str(oldmort01) # structure ## &#39;data.frame&#39;: 6495 obs. of 13 variables: ## $ id : int 765000603 765000669 768000648 770000562 770000707 771000617 771000619 771000638 771000670 772000622 ... ## $ enter : num 94.5 94.3 91.1 89 90 ... ## $ exit : num 95.8 95.8 91.9 89.6 90.2 ... ## $ event : logi TRUE TRUE TRUE TRUE TRUE TRUE ... ## $ birthdate : num 1765 1766 1769 1771 1770 ... ## $ m.id : int NA NA NA NA NA NA NA NA NA NA ... ## $ f.id : int NA NA NA NA NA NA NA NA NA NA ... ## $ sex : Factor w/ 2 levels &quot;male&quot;,&quot;female&quot;: 2 2 2 2 2 2 1 2 2 2 ... ## $ civ : Factor w/ 3 levels &quot;unmarried&quot;,&quot;married&quot;,..: 3 1 3 3 3 3 3 3 3 3 ... ## $ ses.50 : Factor w/ 5 levels &quot;middle&quot;,&quot;unknown&quot;,..: 2 2 2 2 1 2 5 2 2 2 ... ## $ birthplace: Factor w/ 3 levels &quot;parish&quot;,&quot;region&quot;,..: 3 1 1 1 2 1 2 1 1 1 ... ## $ imr.birth : num 22.2 17.7 12.7 16.9 12 ... ## $ region : Factor w/ 3 levels &quot;town&quot;,&quot;industry&quot;,..: 3 2 3 2 3 3 3 2 3 2 ... head(oldmort01) # preview ## id enter exit event birthdate m.id f.id sex civ ses.50 ## 1 765000603 94.510 95.813 TRUE 1765.490 NA NA female widow unknown ## 2 765000669 94.266 95.756 TRUE 1765.734 NA NA female unmarried unknown ## 3 768000648 91.093 91.947 TRUE 1768.907 NA NA female widow unknown ## 4 770000562 89.009 89.593 TRUE 1770.991 NA NA female widow unknown ## 5 770000707 89.998 90.211 TRUE 1770.002 NA NA female widow middle ## 6 771000617 88.429 89.762 TRUE 1771.571 NA NA female widow unknown ## birthplace imr.birth region ## 1 remote 22.20000 rural ## 2 parish 17.71845 industry ## 3 parish 12.70903 rural ## 4 parish 16.90544 industry ## 5 region 11.97183 rural ## 6 parish 13.08594 rural To check how this dataset is constructed, we will need to identify any duplicated id. dup01 &lt;- data.frame(table(oldmort01$id)) dup02 &lt;- dup01[order(-dup01$Freq), ] In the following example, please check When is a new record for the same id created? What are the time-invariant variables? What are the time-variant variables? What does it mean by “TRUE” or “FALSE” in event? How does the time of enter and exit connected with each other? What would happen if there is a gap between two records? dup03 &lt;- oldmort01[oldmort01$id %in% c(&quot;789000771&quot;, &quot;796001158&quot;), ] dup03 ## id enter exit event birthdate m.id f.id sex civ ses.50 ## 536 789000771 70.570 72.059 FALSE 1789.430 NA NA female married unknown ## 537 789000771 72.059 79.391 FALSE 1789.430 NA NA female married unknown ## 538 789000771 79.391 79.947 FALSE 1789.430 NA NA female widow unknown ## 539 789000771 80.010 83.750 FALSE 1789.430 NA NA female widow unknown ## 540 789000771 84.358 87.274 TRUE 1789.430 NA NA female unmarried unknown ## 1472 796001158 63.531 64.020 FALSE 1796.469 NA NA male married farmer ## 1473 796001158 64.020 65.020 FALSE 1796.469 NA NA male widow farmer ## 1474 796001158 65.020 70.019 FALSE 1796.469 NA NA male widow farmer ## 1475 796001158 70.019 80.021 FALSE 1796.469 NA NA male widow farmer ## 1476 796001158 80.021 83.531 FALSE 1796.469 NA NA male widow farmer ## birthplace imr.birth region ## 536 region 19.92337 rural ## 537 region 19.92337 rural ## 538 region 19.92337 rural ## 539 region 19.92337 rural ## 540 region 19.92337 rural ## 1472 parish 19.92337 rural ## 1473 parish 19.92337 rural ## 1474 parish 19.92337 rural ## 1475 parish 19.92337 rural ## 1476 parish 19.92337 rural 4.3 Practice: AddHealth Public datasets There are many ways to construct long-form datasets with counting process. The following procedure is just one way to achieve the goal. Here are a couple of things to construct a long-form dataset with counting process. In practice, measuring outcomes, exposures, confounders, and other variables involves a separate procedure for each one of variables. I personally prefer to divide each measurement as time-variant and time-invariant datasets, respectively. Two variables should be ALWAYS included in every single dataset you are working on - AID and wave (or any other Time variable). Datasets with time-invariant variables can be merged by AID, while those with time-variant variables need to be merged by AID and wave. Time-varying variables will be assigned a single variable name. Let’s say we are to use self-rated health with a variable name of SRH for five waves. The dataset should contain AID, wave, and SRH. The SRH in each wave should be assigned the same name, SRH, and the wave information will be on wave. This way, you can simply “stack up” all 5-wave data to construct the long-form datasets. First, each rda dataset will be loaded and then saved as WAVE0X. After assigning a wave variable for each of them, we will keep the WAVE0X dataset and WX datasets only. #1st wave load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0001/21600-0001-Data.rda&quot;) wave01 &lt;- da21600.0001 wave01$wave &lt;- 1 rm(da21600.0001) w1 = subset(wave01, select = c(AID, wave)) #2nd wave load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0005/21600-0005-Data.rda&quot;) wave02 &lt;- da21600.0005 wave02$wave &lt;- 2 rm(da21600.0005) w2 = subset(wave02, select = c(AID, wave)) #3rd wave load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0008/21600-0008-Data.rda&quot;) wave03 &lt;- da21600.0008 wave03$wave &lt;- 3 rm(da21600.0008) w3 = subset(wave03, select = c(AID, wave)) #4th wave load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0022/21600-0022-Data.rda&quot;) wave04 &lt;- da21600.0022 wave04$wave &lt;- 4 rm(da21600.0022) w4 = subset(wave04, select = c(AID, wave)) # 5th wave load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0032/21600-0032-Data.rda&quot;) wave05 &lt;- da21600.0032 wave05$wave &lt;- 5 rm(da21600.0032) w5 = subset(wave05, select = c(AID, wave)) The complete list of respondents can be obtained by aggregating all WX datasets and then getting the unique AID. The numbers of cases for both occasions are the same. It looks like the first wave contains all respondents - no additional respondents were added. To check this observation, we will see both AID from the first wave and All matched. Because the n didn’t change, we confirmed that WAVE01 contains all respondents of the study. AH01 &lt;- unique(subset(rbind(w1, w2, w3, w4, w5), select = c(AID))) test01 &lt;- cbind(wave01, AH01, by=&quot;AID&quot;) 4.3.1 Generate a complete framework with AID and wave (Optional) I personally prefer working with a “complete framework” containing all AID and wave. lf01 &lt;- rbind(w1, w2, w3, w4, w5) lf &lt;- lf01[order(lf01$AID, lf01$wave), ] Here is the merged (“stacked”) dataset. head(lf01) ## AID wave ## 1 57100270 1 ## 2 57101310 1 ## 3 57103171 1 ## 4 57103869 1 ## 5 57104553 1 ## 6 57104649 1 Sorting by AID and wave, we can easily identify the data structure by AID and wave. This lf dataset is what I call a “framework” of this data source, which is the one that will be used whenever combining or merging datasets. head(lf) ## AID wave ## 1 57100270 1 ## 11339 57100270 3 ## 2 57101310 1 ## 6505 57101310 2 ## 11340 57101310 3 ## 16221 57101310 4 Keep the number of cases (n = 25530) for your record. This number should be the number you expect whenever you merge or stack datasets. count(lf) ## n ## 1 25530 4.3.2 Time-variant variables from each wave In this practice, we will select and rename self-rated health (for all 5-wave) and appetite (only for \\(1^{st}\\) and \\(2^{nd}\\) waves) measures. srh1 &lt;- wave01 %&gt;% dplyr::select(AID, wave, &quot;a_srh&quot; = H1GH1, &quot;a_poorappetite&quot; = H1FS2) srh2 &lt;- wave02 %&gt;% dplyr::select(AID, wave, &quot;a_srh&quot; = H2GH1, &quot;a_poorappetite&quot; = H2GH22) srh3 &lt;- wave03 %&gt;% dplyr::select(AID, wave, &quot;a_srh&quot; = H3GH1) srh4 &lt;- wave04 %&gt;% dplyr::select(AID, wave, &quot;a_srh&quot; = H4GH1) srh5 &lt;- wave05 %&gt;% dplyr::select(AID, wave, &quot;a_srh&quot; = H5ID1) Please note that how to name the “temporary” datasets. I found that using the combination of ‘variable name + wave’ minimizes any confusions later. The ‘rbind’ function requires all datasets have a same numbers of columns. ‘setDT’ and ‘fill=TRUE’ are the functions from a ‘data.table’ package that override this requirement. Now, we have created a long-form dataset (i.e., srh_TV) from five sets of cross-sectional datasets. srh_TV01 &lt;- rbind(setDT(srh1), setDT(srh2), setDT(srh3), setDT(srh4), setDT(srh5), fill=TRUE) srh_TV &lt;- srh_TV01[order(srh_TV01$AID, srh_TV01$wave), ] # 6504, 4834, 4882, 5114, 4196, 25530 head(srh_TV) ## AID wave a_srh a_poorappetite ## 1: 57100270 1 (3) (3) Good (0) (0) Never/rarely ## 2: 57100270 3 (1) (1) Excellent &lt;NA&gt; ## 3: 57101310 1 (4) (4) Fair (1) (1) Sometimes ## 4: 57101310 2 (4) (4) Fair (4) (4) Every day ## 5: 57101310 3 (2) (2) Very good &lt;NA&gt; ## 6: 57101310 4 (3) (3) Good &lt;NA&gt; 4.3.3 Time-invariant By definition, when a variable is time-invariant, only one measure from any variable should be applied to all other waves. In this example, we select sex from the first wave (because of completeness), which will be applied to the whole long-form dataset. demo_TI &lt;- wave01 %&gt;% select(AID, &quot;a_sex&quot; = BIO_SEX) 4.3.4 Merging datasets Once you have selected, created, and modified all required variables by waves, stacking all waves datasets will generate a long-form dataset per wave-person as long as you have keep AID and wave variables for all datasets. In this example, we’ve created three datasets - lf (a framework), demo_TI (time-invariant), and srh_TV (time-variant). Framework + time-invariant (i.e., lf (a framework) and demo_TI (time-invariant)) Final01 &lt;- merge(lf, demo_TI, by = c(&quot;AID&quot;)) head(Final01) ## AID wave a_sex ## 1 57100270 1 (2) (2) Female ## 2 57100270 3 (2) (2) Female ## 3 57101310 1 (2) (2) Female ## 4 57101310 2 (2) (2) Female ## 5 57101310 3 (2) (2) Female ## 6 57101310 4 (2) (2) Female Framework + time-invariant + time-variant (i.e., Final01 + srh_TV (time-variant)) Final02 &lt;- merge(Final01, srh_TV, by = c(&quot;AID&quot;, &quot;wave&quot;)) head(Final02) ## AID wave a_sex a_srh a_poorappetite ## 1 57100270 1 (2) (2) Female (3) (3) Good (0) (0) Never/rarely ## 2 57100270 3 (2) (2) Female (1) (1) Excellent &lt;NA&gt; ## 3 57101310 1 (2) (2) Female (4) (4) Fair (1) (1) Sometimes ## 4 57101310 2 (2) (2) Female (4) (4) Fair (4) (4) Every day ## 5 57101310 3 (2) (2) Female (2) (2) Very good &lt;NA&gt; ## 6 57101310 4 (2) (2) Female (3) (3) Good &lt;NA&gt; 4.3.5 Define event, enter, and exit The event can be defined as your outcomes. Depending on the nature of outcomes, it could be a multiple or repetitive events, requiring more complex survival modeling with more assumptions. Using lag/lead(wave) Final03 &lt;- Final02 %&gt;% group_by(AID) %&gt;% dplyr::mutate( enter = lag(wave), exit = wave ) %&gt;% ungroup() Final03$enter[Final03$wave == 1 &amp; is.na(Final03$enter)] &lt;- 0 Because we used wave as an example, it may look more complicated than necessary - for example, we may simply use enter = exit - 1. However, this lag/lead function is required when working with the actual date which interval is not always equal to 1. "],["survival-models-specification-estimation-and-interpretation.html", "Chapter 5 Survival models: specification, estimation, and interpretation 5.1 Nonparametric models 5.2 Semi-parametric models: Cox Regression 5.3 Logistic regression 5.4 Linear regression 5.5 Weibull model 5.6 Exponential model 5.7 Gompertz model 5.8 Graphs", " Chapter 5 Survival models: specification, estimation, and interpretation Let’s think some some feasible models addressing how the survival varies by sex, region, and infant mortality of the cohort, using oldmort01 dataset. Here are some possible models depending on the outcome: Descriptive models for survival time Linear or Poisson regression on the ‘survival time’, which can be defined as the time of death (i.e., ‘exit’). We may need to subset only those who died, potentially resulting in considerable loss of data. Logistic regression for the event, death. How would you incorporate “survival time” in this model? Semiparametric survival regression models parametric survival regression models 5.1 Nonparametric models Let’s fit Kaplan-Meier (KM) and Nelson-Aalen (NA) estimators using the oldmort01 dataset from the eha package. Kaplan-Meier (KM) survival estimator ## KM bysex_KM &lt;- survfit(Surv(enter, exit, event) ~ sex, data=oldmort01, conf.type=&quot;log-log&quot;) ## Tables bysex_KM ## Call: survfit(formula = Surv(enter, exit, event) ~ sex, data = oldmort01, ## conf.type = &quot;log-log&quot;) ## ## records n events median 0.95LCL 0.95UCL ## sex=male 2884 1390 854 75.1 74.3 75.6 ## sex=female 3611 1833 1117 76.7 76.1 77.1 ##summary(bysex) summary(bysex_KM, times=c(60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110)) # add time points ## Call: survfit(formula = Surv(enter, exit, event) ~ sex, data = oldmort01, ## conf.type = &quot;log-log&quot;) ## ## sex=male ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 60 1390 0 1.00000 0.00000 1.000000 1.0000 ## 65 1017 183 0.85817 0.00974 0.837865 0.8761 ## 70 697 168 0.70232 0.01352 0.674905 0.7279 ## 75 428 184 0.50490 0.01576 0.473598 0.5353 ## 80 191 171 0.28095 0.01561 0.250745 0.3119 ## 85 55 105 0.10892 0.01237 0.086192 0.1346 ## 90 12 34 0.03311 0.00841 0.019374 0.0526 ## 95 1 8 0.00392 0.00381 0.000404 0.0197 ## ## sex=female ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 60 1833 0 1.0000 0.00000 1.000000 1.00000 ## 65 1416 166 0.9022 0.00723 0.886989 0.91541 ## 70 1034 205 0.7610 0.01094 0.738691 0.78161 ## 75 669 238 0.5736 0.01343 0.546771 0.59938 ## 80 318 236 0.3477 0.01415 0.320058 0.37547 ## 85 115 167 0.1527 0.01192 0.130179 0.17687 ## 90 27 80 0.0380 0.00705 0.025840 0.05359 ## 95 5 21 0.0075 0.00333 0.002894 0.01662 ## 100 1 4 0.0015 0.00150 0.000153 0.00812 Nelson-Aalen (NA) estimator ## NA bysex_NA &lt;- survfit(Surv(enter, exit, event) ~ sex, data=oldmort01, conf.type=&quot;log-log&quot;, type=&quot;fh&quot;) # an option for NA estimator ## Tables bysex_NA ## Call: survfit(formula = Surv(enter, exit, event) ~ sex, data = oldmort01, ## conf.type = &quot;log-log&quot;, type = &quot;fh&quot;) ## ## records n events median 0.95LCL 0.95UCL ## sex=male 2884 1390 854 75.1 74.3 75.6 ## sex=female 3611 1833 1117 76.7 76.1 77.1 ##summary(bysex) summary(bysex_NA, times=c(60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110)) # add time points ## Call: survfit(formula = Surv(enter, exit, event) ~ sex, data = oldmort01, ## conf.type = &quot;log-log&quot;, type = &quot;fh&quot;) ## ## sex=male ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 60 1390 0 1.00000 0.00000 1.00000 1.0000 ## 65 1017 183 0.85822 0.00974 0.83793 0.8762 ## 70 697 168 0.70245 0.01352 0.67504 0.7280 ## 75 428 184 0.50514 0.01575 0.47385 0.5356 ## 80 191 171 0.28138 0.01561 0.25118 0.3123 ## 85 55 105 0.10962 0.01239 0.08685 0.1353 ## 90 12 34 0.03418 0.00849 0.02024 0.0538 ## 95 1 8 0.00583 0.00449 0.00101 0.0216 ## ## sex=female ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 60 1833 0 1.00000 0.00000 1.000000 1.00000 ## 65 1416 166 0.90220 0.00723 0.887022 0.91543 ## 70 1034 205 0.76103 0.01094 0.738776 0.78169 ## 75 669 238 0.57371 0.01342 0.546935 0.59953 ## 80 318 236 0.34799 0.01415 0.320348 0.37575 ## 85 115 167 0.15315 0.01193 0.130627 0.17734 ## 90 27 80 0.03863 0.00710 0.026391 0.05434 ## 95 5 21 0.00824 0.00347 0.003349 0.01759 ## 100 1 4 0.00228 0.00183 0.000381 0.00911 Overall survival and hazard curves for the population ## Plots par(mfrow = c(1, 2))# Two panels, &quot;one row, two columns&quot;. with(oldmort01, plot(Surv(enter, exit, event), fun = &quot;cumhaz&quot;, main = &quot;Cumulativa hazards function&quot;, xlab = &quot;Duration&quot;)) with(oldmort01, plot(Surv(enter, exit, event), main = &quot;Survival function&quot;, xlab = &quot;Duration&quot;)) Comparison between Male and Female # Plots par(mfrow = c(1, 2))# Two panels, &quot;one row, two columns&quot;. plot(bysex_KM, ylab = &quot;Survival probability&quot;, xlab = &quot;Time&quot;, mark.time = T, main=&quot;Kaplan-Meier survival curve&quot;) legend(&quot;topleft&quot;, c(&quot;Male&quot;,&quot;Female&quot;), lty=c(&quot;solid&quot;,&quot;dashed&quot;), col=c(&quot;black&quot;,&quot;red&quot;)) #abline(h = 0.5, col = &quot;sienna&quot;, lty = 3) plot(bysex_NA, ylab = &quot;Cumulative hazard&quot;, xlab = &quot;Time&quot;, mark.time = T, fun=&quot;cumhaz&quot;, main=&quot;Nelson-Aalen cumulative hazard curve&quot;) legend(&quot;topleft&quot;, c(&quot;Male&quot;,&quot;Female&quot;), lty=c(&quot;solid&quot;,&quot;dashed&quot;), col=c(&quot;black&quot;,&quot;red&quot;)) #abline(h = 0.5, col = &quot;sienna&quot;, lty = 3) For a better plot for comparisons library(ggfortify) library(ggplot2) autoplot(bysex_KM, ylab = &quot;Survival probabilities&quot;, xlab = &quot;Survival time&quot;, #mark.time = T, main=&quot;Kaplan-Meier survival curve estimate with 95% CIs&quot; ) 5.2 Semi-parametric models: Cox Regression 5.2.1 Model specification \\[h(t)=h_0 (t)\\exp(b_1\\times D_f + b_2 \\times D_{ind} + b_3 \\times D_{rural} + b_4 \\times X_{IMR})\\] 5.2.2 Estimation oldmort_cox &lt;- coxreg(Surv(enter, exit, event) ~ sex + region + imr.birth, data = oldmort01) print(summary(oldmort_cox), digits = 4) ## Covariate Mean Coef Rel.Risk S.E. LR p ## sex 0.0001 ## male 0.406 0 1 (reference) ## female 0.594 -0.185 0.831 0.046 ## region 0.0013 ## town 0.111 0 1 (reference) ## industry 0.326 0.225 1.252 0.087 ## rural 0.563 0.069 1.071 0.087 ## imr.birth 15.162 0.005 1.005 0.007 0.5009 ## ## Events 1971 ## Total time at risk 37824 ## Max. log. likelihood -13563 ## LR test statistic 31.41 ## Degrees of freedom 4 ## Overall p-value 2.52611e-06 b_cox &lt;- coef(oldmort_cox) expb_cox &lt;- exp(coef(oldmort_cox)) # Plots par(mfrow = c(1, 2), las = 1) plot(oldmort_cox, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Survival&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(oldmort_cox, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) Our estimated model is \\(h(t)=h_0 (t)\\exp(0.2249025)\\)\\(sex_{female} + (0.0690311)\\)\\(region_{industry} + (0.0045481)\\)\\(region_{rural} + (NA)\\)$IMR) To ease interpretation, we exponentiate coefficients (and CIs). exp(coef(oldmort_cox)) ## sexfemale regionindustry regionrural imr.birth ## 0.8308988 1.2522007 1.0714696 1.0045585 5.2.3 Interpretations What is the metric of \\(y\\) and \\(b_i\\), respectively? Interpret \\(b_0, b_1,\\) and \\(b_2\\), respectively. What is the difference between coefficients and \\(\\exp\\)(coefficients)? Specify the metric. What is the interpretation when 1) \\(b_i = 0\\), 2) \\(b_i &lt; 0\\), or 3) \\(b_i &gt; 0\\)? What is the interpretation when 1) \\(\\exp(b_i) = 1\\), 2) \\(\\exp(b_i) &lt; 1\\), or 3) \\(\\exp(b_i) &gt; 1\\)? How would you compare \\(p(death)\\) between two groups of people below? Is the effect additive or multiplicative? What is the estimated \\(p(death)\\) for those who with sex = 0, region = 0, and IMR = 0 vs. those who with sex = 1, region = 0, and IMR = 0? What is the estimated \\(p(death)\\) for those who with sex = 0, region = 2, and IMR = 90 vs. those who with sex = 1, region = 2, and IMR = 90? 5.3 Logistic regression To fit logistic regression, ‘death’ variable was created. oldmort01$death &lt;- ifelse(oldmort01$event == &quot;TRUE&quot;, 1, 0) 5.3.1 Model specification \\[ \\ln \\left( \\frac{p(y)}{1-p(y)} \\right) = b_0 + b_1\\times D_f + b_2 \\times D_{ind} + b_3 \\times D_{rural} + b_4 \\times X_{IMR}\\] 5.3.2 Estimation Logistic model was fitted as below. oldmort_log &lt;- glm(death ~ sex + region + imr.birth, data=oldmort01, family = binomial(link = &quot;logit&quot;)) summary(oldmort_log) ## ## Call: ## glm(formula = death ~ sex + region + imr.birth, family = binomial(link = &quot;logit&quot;), ## data = oldmort01) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.9467 -0.8371 -0.8105 1.4506 1.6661 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.003482 0.166455 -6.029 1.65e-09 *** ## sexfemale 0.073055 0.054619 1.338 0.181050 ## regionindustry 0.378124 0.100516 3.762 0.000169 *** ## regionrural 0.111579 0.099098 1.126 0.260188 ## imr.birth -0.004146 0.007756 -0.534 0.593010 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 7972.9 on 6494 degrees of freedom ## Residual deviance: 7944.9 on 6490 degrees of freedom ## AIC: 7954.9 ## ## Number of Fisher Scoring iterations: 4 b_log = coef(oldmort_log) expb = exp(coef(oldmort_log)) Our estimated model is \\(\\ln \\left( \\frac{p(y)}{1-p(y)} \\right)\\) = (-1.0034822) + (0.0730548)\\(\\times\\)sex_{female} + (0.3781242)\\(\\times\\)region_{industry} + (0.1115792)\\(\\times\\)region_{rural} + (-0.0041455)\\(\\times\\)IMR To ease interpretation, we exponentiate coefficients (and CIs). exp(coef(oldmort_log)) ## (Intercept) sexfemale regionindustry regionrural imr.birth ## 0.3666006 1.0757895 1.4595443 1.1180423 0.9958631 5.3.3 Interpretation What is the metric of \\(y\\) and \\(b_i\\), respectively? Interpret \\(b_0, b_1,\\) and \\(b_2\\), respectively. What is the difference between coefficients and \\(\\exp\\)(coefficients)? Specify the metric. What is the interpretation when 1) \\(b_i = 0\\), 2) \\(b_i &lt; 0\\), or 3) \\(b_i &gt; 0\\)? What is the interpretation when 1) \\(exp(b_i) = 1\\), 2) \\(exp(b_i) &lt; 1\\), or 3) \\(exp(b_i) &gt; 1\\)? How would you compare \\(p(death)\\) between two groups of people below? Is the effect additive or multiplicative? What is the estimated \\(p(death)\\) for those who with sex = 0, region = 0, and IMR = 0 vs. those who with sex = 1, region = 0, and IMR = 0? What is the estimated \\(p(death)\\) for those who with sex = 0, region = 2, and IMR = 90 vs. those who with sex = 1, region = 2, and IMR = 90? 5.4 Linear regression 5.4.1 Model specification \\[ Y_{Time\\;to\\; death} = b_0 + b_1\\times D_f + b_2 \\times D_{ind} + b_3 \\times D_{rural} + b_4 \\times X_{IMR} \\] 5.4.2 Estimation To fit linear model, we need to subset data for the death and use ‘exit’ as an outcome. oldmort02 &lt;- oldmort01[oldmort01$death == 1,] oldmort_lm &lt;- glm(exit ~ sex + region + imr.birth, data=oldmort02, family = &quot;gaussian&quot;) summary(oldmort_lm) ## ## Call: ## glm(formula = exit ~ sex + region + imr.birth, family = &quot;gaussian&quot;, ## data = oldmort02) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -14.6605 -6.3367 -0.1812 5.4018 25.3607 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 71.99777 1.12285 64.120 &lt; 2e-16 *** ## sexfemale 1.90403 0.35249 5.402 7.4e-08 *** ## regionindustry 2.07598 0.66429 3.125 0.00180 ** ## regionrural 1.80560 0.66531 2.714 0.00671 ** ## imr.birth -0.09621 0.05156 -1.866 0.06219 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 60.06622) ## ## Null deviance: 120769 on 1970 degrees of freedom ## Residual deviance: 118090 on 1966 degrees of freedom ## AIC: 13673 ## ## Number of Fisher Scoring iterations: 2 b_lm = coef(oldmort_lm) Thus, our estimated model is Time to death (\\(t\\)) = (71.9977676) + (1.9040306)\\(\\times\\)sex_{female} + (2.0759823)\\(\\times\\)region_{industry} + (1.8056008)\\(\\times\\)region_{rural} + (-0.0962143)\\(\\times\\)IMR 5.4.3 Interpretation What is the metric of \\(y\\) and \\(b_i\\), respectively? Interpret \\(b_0, b_1,\\) and \\(b_2\\), respectively. What is the interpretation when 1) \\(b_i = 0\\), 2) \\(b_i &lt; 0\\), or 3) \\(b_i &gt; 0\\)? How would you compare the time to death between two groups of people below? Is the effect additive or multiplicative? What is the estimated time to death for those who with sex = 0, region = 0, and IMR = 0 vs. those who with sex = 1, region = 0, and IMR = 0? What is the estimated time to death for those who with sex = 0, region = 2, and IMR = 90 vs. those who with sex = 1, region = 2, and IMR = 90? 5.5 Weibull model 5.5.1 Model specification \\[h(t)=h_0 (t)\\exp(b_1\\times D_f + b_2 \\times D_{ind} + b_3 \\times D_{rural} + b_4 \\times X_{IMR})\\] The full hazard function for the Weibull PH model is \\[h(t)=\\exp(b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)pt^{p-1}\\] Therefore, in terms of \\(S(t)\\), \\[ S(t)=\\exp(-(b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)t^p) \\] \\(p \\; (0&lt;p)\\) is a shape parameter. 5.5.2 Estimation # Models oldmort_wei &lt;- phreg(Surv(enter, exit, event) ~ sex + region + imr.birth, data = oldmort01, dist = &quot;weibull&quot;) # Table #print(summary(oldmort_wei), digits = 4) oldmort_wei ## Call: ## phreg(formula = Surv(enter, exit, event) ~ sex + region + imr.birth, ## data = oldmort01, dist = &quot;weibull&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## sex ## male 0.406 0 1 (reference) ## female 0.594 -0.185 0.831 0.046 0.000 ## region ## town 0.111 0 1 (reference) ## industry 0.326 0.223 1.250 0.087 0.010 ## rural 0.563 0.065 1.067 0.087 0.456 ## imr.birth 15.162 0.005 1.005 0.007 0.452 ## ## log(scale) 4.362 0.019 0.000 ## log(shape) 2.083 0.027 0.000 ## ## Events 1971 ## Total time at risk 37824 ## Max. log. likelihood -7281.2 ## LR test statistic 31.82 ## Degrees of freedom 4 ## Overall p-value 2.08157e-06 b_wei &lt;- coef(oldmort_wei) expb_wei &lt;- exp(coef(oldmort_wei)) # Plots par(mfrow = c(1, 2), las = 1) plot(oldmort_wei, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Survival&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(oldmort_wei, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) To ease interpretation, we exponentiate coefficients (and CIs). exp(coef(oldmort_wei)) ## sexfemale regionindustry regionrural imr.birth log(scale) ## 0.8308202 1.2499929 1.0666983 1.0050654 78.4097920 ## log(shape) ## 8.0304270 5.5.3 Interpretations What is the metric of \\(y\\) and \\(b_i\\), respectively? Interpret \\(b_0, b_1,\\) and \\(b_2\\), respectively. What is the difference between coefficients and \\(\\exp\\)(coefficients)? Specify the metric. What is the interpretation when 1) \\(b_i = 0\\), 2) \\(b_i &lt; 0\\), or 3) \\(b_i &gt; 0\\)? What is the interpretation when 1) \\(\\exp(b_i) = 1\\), 2) \\(\\exp(b_i) &lt; 1\\), or 3) \\(\\exp(b_i) &gt; 1\\)? How would you compare \\(h(time\\;to\\;death)\\) between two groups of people below? Is the effect additive or multiplicative? What is the estimated \\(h(time\\;to\\;death)\\) for those who with sex = 0, region = 0, and IMR = 0 vs. those who with sex = 1, region = 0, and IMR = 0? What is the estimated \\(h(time\\;to\\;death)\\) for those who with sex = 0, region = 2, and IMR = 90 vs. those who with sex = 1, region = 2, and IMR = 90? 5.6 Exponential model 5.6.1 Model specification \\[h(t)=h_0 (t)\\exp(b_1\\times D_f + b_2 \\times D_{ind} + b_3 \\times D_{rural} + b_4 \\times X_{IMR})\\] Exponential model is a specific case of Weibull family when \\(p\\)=1. The full hazard function is \\[h(t)=\\exp(b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)pt^{p-1}=\\exp(b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)\\] Therefore, in terms of \\(S(t)\\), \\[ S(t)=\\exp(-(b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)t^p)=\\exp(-(b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)t) \\] 5.6.2 Estimation # Models oldmort_exp &lt;- phreg(Surv(enter, exit, event) ~ sex + region + imr.birth, shape=1, data = oldmort01, dist = &quot;weibull&quot;) # Table #print(summary(oldmort_wei), digits = 4) oldmort_exp ## Call: ## phreg(formula = Surv(enter, exit, event) ~ sex + region + imr.birth, ## data = oldmort01, dist = &quot;weibull&quot;, shape = 1) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## sex ## male 0.406 0 1 (reference) ## female 0.594 -0.100 0.905 0.046 0.029 ## region ## town 0.111 0 1 (reference) ## industry 0.326 0.395 1.484 0.086 0.000 ## rural 0.563 0.167 1.182 0.086 0.051 ## imr.birth 15.162 0.003 1.003 0.007 0.621 ## ## log(scale) 3.178 0.145 0.000 ## ## Shape is fixed at 1 ## ## Events 1971 ## Total time at risk 37824 ## Max. log. likelihood -7774.3 ## LR test statistic 39.77 ## Degrees of freedom 4 ## Overall p-value 4.82752e-08 b_exp &lt;- coef(oldmort_exp) expb_exp &lt;- exp(coef(oldmort_exp)) # Plots par(mfrow = c(1, 2), las = 1) plot(oldmort_exp, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Survival&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(oldmort_exp, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) To ease interpretation, we exponentiate coefficients (and CIs). exp(coef(oldmort_exp)) ## sexfemale regionindustry regionrural imr.birth log(scale) ## 0.9052028 1.4838456 1.1817648 1.0032832 23.9906740 5.6.3 Interpretations What is the metric of \\(y\\) and \\(b_i\\), respectively? Interpret \\(b_0, b_1,\\) and \\(b_2\\), respectively. What is the difference between coefficients and \\(\\exp\\)(coefficients)? Specify the metric. What is the interpretation when 1) \\(b_i = 0\\), 2) \\(b_i &lt; 0\\), or 3) \\(b_i &gt; 0\\)? What is the interpretation when 1) \\(\\exp(b_i) = 1\\), 2) \\(\\exp(b_i) &lt; 1\\), or 3) \\(\\exp(b_i) &gt; 1\\)? How would you compare \\(h(time\\;to\\;death)\\) between two groups of people below? Is the effect additive or multiplicative? What is the estimated \\(h(time\\;to\\;death)\\) for those who with sex = 0, region = 0, and IMR = 0 vs. those who with sex = 1, region = 0, and IMR = 0? What is the estimated \\(h(time\\;to\\;death)\\) for those who with sex = 0, region = 2, and IMR = 90 vs. those who with sex = 1, region = 2, and IMR = 90? 5.7 Gompertz model 5.7.1 Model specification \\[h(t)=h_0 (t)\\exp(b_1\\times D_f + b_2 \\times D_{ind} + b_3 \\times D_{rural} + b_4 \\times X_{IMR})\\] Gompertz model is characterized by an exponentially increasing hazard function with fixed rate \\(r\\) (\\(-\\infty &lt; r &lt; \\infty\\)). when \\(r &lt; 0\\), the hazard function \\(h\\) is decreasing “too fast” to define a proper survival function, and \\(r=0\\) gives the exponential distribution as a special case. And for each fixed \\(r\\), the family of distributions indexed by \\(p &gt; 0\\) constitutes a proportional hazards family of distributions, and the corresponding regression model is written as Göran Broström, https://cran.r-project.org/web/packages/eha/vignettes/gompertz.html \\[h(t)=\\exp(b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n)pe^{rt}\\] 5.7.2 Estimation # Models oldmort_gomp &lt;- phreg(Surv(enter, exit, event) ~ sex + region + imr.birth, data = oldmort01, dist = &quot;gompertz&quot;) # Table #print(summary(parm), digits = 4) oldmort_gomp ## Call: ## phreg(formula = Surv(enter, exit, event) ~ sex + region + imr.birth, ## data = oldmort01, dist = &quot;gompertz&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## sex ## male 0.406 0 1 (reference) ## female 0.594 -0.188 0.829 0.046 0.000 ## region ## town 0.111 0 1 (reference) ## industry 0.326 0.222 1.248 0.087 0.011 ## rural 0.563 0.067 1.069 0.087 0.438 ## imr.birth 15.162 0.005 1.005 0.007 0.433 ## ## log(scale) 2.353 0.030 0.000 ## log(shape) -7.410 0.286 0.000 ## ## Events 1971 ## Total time at risk 37824 ## Max. log. likelihood -7280.6 ## LR test statistic 31.79 ## Degrees of freedom 4 ## Overall p-value 2.11245e-06 b_gomp &lt;- coef(oldmort_gomp) expb_gomp &lt;- exp(coef(oldmort_gomp)) # Plots par(mfrow = c(1, 2), las = 1) plot(oldmort_gomp, fn = &quot;sur&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;Survival&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) plot(oldmort_gomp, fn = &quot;cum&quot;, main = &quot;&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;hazard&quot;, #xlim=c(0, 1) #ylim=c(ymin, ymax) ) To ease interpretation, we exponentiate coefficients (and CIs). exp(coef(oldmort_gomp)) ## sexfemale regionindustry regionrural imr.birth log(scale) ## 8.286745e-01 1.248116e+00 1.069401e+00 1.005278e+00 1.051873e+01 ## log(shape) ## 6.053369e-04 5.7.3 Interpretations What is the metric of \\(y\\) and \\(b_i\\), respectively? Interpret \\(b_0, b_1,\\) and \\(b_2\\), respectively. What is the difference between coefficients and \\(\\exp\\)(coefficients)? Specify the metric. What is the interpretation when 1) \\(b_i = 0\\), 2) \\(b_i &lt; 0\\), or 3) \\(b_i &gt; 0\\)? What is the interpretation when 1) \\(\\exp(b_i) = 1\\), 2) \\(\\exp(b_i) &lt; 1\\), or 3) \\(\\exp(b_i) &gt; 1\\)? How would you compare \\(h(time\\;to\\;death)\\) between two groups of people below? Is the effect additive or multiplicative? What is the estimated \\(h(time\\;to\\;death)\\) for those who with sex = 0, region = 0, and IMR = 0 vs. those who with sex = 1, region = 0, and IMR = 0? What is the estimated \\(h(time\\;to\\;death)\\) for those who with sex = 0, region = 2, and IMR = 90 vs. those who with sex = 1, region = 2, and IMR = 90? 5.8 Graphs The following figures summarize cumulative hazard curves by different survival models. # Plots par(mfrow = c(2, 2), las = 1) plot(oldmort_cox, fn = &quot;cum&quot;, main = &quot;Cox&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;&quot;, #xlim=c(0, 1) ylim=c(0, 10) ) plot(oldmort_wei, fn = &quot;cum&quot;, main = &quot;Weibull&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;&quot;, #xlim=c(0, 1) ylim=c(0, 10) ) plot(oldmort_exp, fn = &quot;cum&quot;, main = &quot;Exponential&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;&quot;, #xlim=c(0, 1) ylim=c(0, 10) ) plot(oldmort_gomp, fn = &quot;cum&quot;, main = &quot;Gompertz&quot;, #xlab=&quot;Duration (year)&quot;, ylab=&quot;&quot;, #xlim=c(0, 1) ylim=c(0, 10) ) "],["add-health-project.html", "Chapter 6 Add Health Project 6.1 Library 6.2 Access datasets 6.3 Load 5-wave sample 6.4 Long-form dataset (wave-person) 6.5 Exploring variables in Add Health 6.6 Outcomes, exposures, and confounders 6.7 Demographic variables - time-invariant 6.8 Merging datasets 6.9 Data management, recoding, and so on 6.10 Analytic approach", " Chapter 6 Add Health Project 6.1 Library library(tidyverse) library(data.table) library(lme4) ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following objects are masked from &#39;package:tidyr&#39;: ## ## expand, pack, unpack library(Matrix) 6.2 Access datasets Let’s use the public datasets available at https://www.icpsr.umich.edu/web/ICPSR/studies/21600?archive=ICPSR&amp;q=21600 6.3 Load 5-wave sample First, each RDA dataset will be loaded and then saved as WAVE0X. After assigning a WAVE variable, we will keep the WAVE0X dataset and WX datasets only. load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0001/21600-0001-Data.rda&quot;) wave01 &lt;- da21600.0001 wave01$wave &lt;- 1 rm(da21600.0001) w1 = subset(wave01, select = c(AID, wave)) load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0005/21600-0005-Data.rda&quot;) wave02 &lt;- da21600.0005 wave02$wave &lt;- 2 rm(da21600.0005) w2 = subset(wave02, select = c(AID, wave)) load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0008/21600-0008-Data.rda&quot;) wave03 &lt;- da21600.0008 wave03$wave &lt;- 3 rm(da21600.0008) w3 = subset(wave03, select = c(AID, wave)) load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0022/21600-0022-Data.rda&quot;) wave04 &lt;- da21600.0022 wave04$wave &lt;- 4 rm(da21600.0022) w4 = subset(wave04, select = c(AID, wave)) load(&quot;~/pCloudDrive/Datasets/AddHealthPublic/ICPSR_21600/DS0032/21600-0032-Data.rda&quot;) wave05 &lt;- da21600.0032 wave05$wave &lt;- 5 rm(da21600.0032) w5 = subset(wave05, select = c(AID, wave)) The complete list of respondents can be obtained by aggregating all WX datasets and then getting the unique AID. aaa &lt;- rbind(w1, w2, w3, w4, w5) AH01 &lt;- unique(subset(rbind(w1, w2, w3, w4, w5), select = c(AID))) It looks like the first wave contains all respondents - no addtional respondents were added. To check this observation, we will see both AID from the first wave and All matched. test01 &lt;- cbind(wave01, AH01, by=&quot;AID&quot;) Because the n didn’t change, we confirmed that WAVE01 contains all respondents of the study. 6.4 Long-form dataset (wave-person) Aggregating WX datasets will generate a long-form dataset per wave-person. lf01 &lt;- rbind(w1, w2, w3, w4, w5) lf &lt;- lf01[order(lf01$AID, lf01$wave), ] # 6504, 4834, 4882, 5114, 4196, 25530 We will save LF for the later use. 6.5 Exploring variables in Add Health Use “Variables” or other documentations at https://www.icpsr.umich.edu/web/ICPSR/studies/21600?archive=ICPSR&amp;q=21600 6.6 Outcomes, exposures, and confounders Let’s assume we are interested in the BMI trajectory, which calculation requires both weight and height in each wave. We also keep and rename exposures and confounders. This process requires getting back and force to add, rename, and remove a set of variables. To note, whenever keeping variables in your datasets, add AID and wave as default variables. It is a good practice to keep the variable names consistent - for example, variables for adolescence will have “a_”, while those for adolescence’s parents will have “p_”, and those of adolescence’s offspring will have “0_”. By keeping all variable selection in one place, you can minimize any confusions in managing variables later. So, it looks like either lbs or kg, cm or inch was used for weight and height. Also, there are multiple variables for each weight or height, requiring your further study about which one is better than others. Here, I will simply go with the following variables, using BMI formula at https://www.cdc.gov/healthyweight/assessing/bmi/childrens_BMI/childrens_BMI_formula.html#:~:text=The%20formula%20for%20BMI%20is,to%20convert%20this%20to%20meters.&amp;text=When%20using%20English%20measurements%2C%20pounds,2%20to%20kg%2Fm2. bmiwgt1 &lt;- wave01 %&gt;% select(AID, wave, &quot;a_srh&quot; = H1GH1, &quot;a_wgt_lbs&quot; = H1GH60, &quot;a_hgt_ft&quot; = H1GH59A, &quot;a_hgt_in&quot; = H1GH59B, &quot;a_weightimage&quot; = H1GH28, &quot;a_poorappetite&quot; = H1FS2) summary(bmiwgt1) ## AID wave a_srh a_wgt_lbs ## 57100270: 1 Min. :1 (1) (1) Excellent:1847 Min. : 50.0 ## 57101310: 1 1st Qu.:1 (2) (2) Very good:2608 1st Qu.:118.0 ## 57103171: 1 Median :1 (3) (3) Good :1605 Median :135.0 ## 57103869: 1 Mean :1 (4) (4) Fair : 408 Mean :141.1 ## 57104553: 1 3rd Qu.:1 (5) (5) Poor : 28 3rd Qu.:160.0 ## 57104649: 1 Max. :1 NA&#39;s : 8 Max. :360.0 ## (Other) :6498 NA&#39;s :156 ## a_hgt_ft a_hgt_in ## (4) (4) 4 feet: 214 (04) (4) 4 inches: 693 ## (5) (5) 5 feet:5448 (06) (6) 6 inches: 669 ## (6) (6) 6 feet: 758 (03) (3) 3 inches: 629 ## NA&#39;s : 84 (02) (2) 2 inches: 569 ## (05) (5) 5 inches: 562 ## (Other) :3287 ## NA&#39;s : 95 ## a_weightimage a_poorappetite ## (1) (1) Very underweight : 128 (0) (0) Never/rarely :4192 ## (2) (2) Slightly underweight : 935 (1) (1) Sometimes :1744 ## (3) (3) About the right weight:3381 (2) (2) A lot of the time : 410 ## (4) (4) Slightly overweight :1808 (3) (3) Most/all of the time: 141 ## (5) (5) Very overweight : 238 NA&#39;s : 17 ## NA&#39;s : 14 ## bmiwgt2 &lt;- wave02 %&gt;% select(AID, wave, &quot;a_srh&quot; = H2GH1, &quot;a_wgt_lbs&quot; = H2GH53, &quot;a_hgt_ft&quot; = H2WS16HF, &quot;a_hgt_in&quot; = H2WS16HI, &quot;a_weightimage&quot; = H2GH30, &quot;a_poorappetite&quot; = H2GH22) summary(bmiwgt2) ## AID wave a_srh a_wgt_lbs ## 57101310: 1 Min. :2 (1) (1) Excellent:1434 Min. : 60.0 ## 57103869: 1 1st Qu.:2 (2) (2) Very good:1923 1st Qu.:120.0 ## 57104649: 1 Median :2 (3) (3) Good :1179 Median :140.0 ## 57104676: 1 Mean :2 (4) (4) Fair : 286 Mean :145.7 ## 57109625: 1 3rd Qu.:2 (5) (5) Poor : 10 3rd Qu.:163.0 ## 57110897: 1 Max. :2 NA&#39;s : 2 Max. :350.0 ## (Other) :4828 NA&#39;s :86 ## a_hgt_ft a_hgt_in ## (4) (4) 4 feet: 88 (06) (6) 6 inches: 537 ## (5) (5) 5 feet:4077 (05) (5) 5 inches: 462 ## (6) (6) 6 feet: 638 (04) (4) 4 inches: 461 ## NA&#39;s : 31 (07) (7) 7 inches: 459 ## (02) (2) 2 inches: 415 ## (Other) :2469 ## NA&#39;s : 31 ## a_weightimage a_poorappetite ## (1) (1) Very underweight : 56 (0) (0) Never :2312 ## (2) (2) Slightly underweight : 697 (1) (1) Just a few times :1834 ## (3) (3) About the right weight:2576 (2) (2) About once a week: 508 ## (4) (4) Slightly overweight :1338 (3) (3) Almost every day : 136 ## (5) (5) Very overweight : 162 (4) (4) Every day : 42 ## NA&#39;s : 5 NA&#39;s : 2 ## bmiwgt3 &lt;- wave03 %&gt;% select(AID, wave, &quot;a_srh&quot; = H3GH1, &quot;a_wgt_lbs&quot; = H3DA44, &quot;a_hgt_ft&quot; = H3HGT_F, &quot;a_hgt_in&quot; = H3HGT_I) summary(bmiwgt3) ## AID wave a_srh a_wgt_lbs ## 57100270: 1 Min. :3 (1) (1) Excellent:1601 Min. : 80.0 ## 57101310: 1 1st Qu.:3 (2) (2) Very good:2000 1st Qu.:136.0 ## 57103869: 1 Median :3 (3) (3) Good :1055 Median :160.0 ## 57104676: 1 Mean :3 (4) (4) Fair : 206 Mean :168.5 ## 57109625: 1 3rd Qu.:3 (5) (5) Poor : 20 3rd Qu.:190.0 ## 57111071: 1 Max. :3 Max. :430.0 ## (Other) :4876 NA&#39;s :111 ## a_hgt_ft a_hgt_in ## (4) (4) 4 feet: 84 (04) (4) 4 inches: 470 ## (5) (5) 5 feet:3913 (06) (6) 6 inches: 458 ## (6) (6) 6 feet: 732 (02) (2) 2 inches: 448 ## (7) (7) 7 feet: 1 (03) (3) 3 inches: 424 ## NA&#39;s : 152 (07) (7) 7 inches: 409 ## (Other) :2518 ## NA&#39;s : 155 bmiwgt4 &lt;- wave04 %&gt;% select(AID, wave, &quot;a_srh&quot; = H4GH1, &quot;a_wgt_lbs&quot; = H4GH6, &quot;a_hgt_ft&quot; = H4GH5F, &quot;a_hgt_in&quot; = H4GH5I) summary(bmiwgt4) ## AID wave a_srh a_wgt_lbs ## 57101310: 1 Min. :4 (1) (1) Excellent: 979 Min. : 18.0 ## 57103869: 1 1st Qu.:4 (2) (2) Very good:1963 1st Qu.:150.0 ## 57109625: 1 Median :4 (3) (3) Good :1683 Median :178.0 ## 57111071: 1 Mean :4 (4) (4) Fair : 434 Mean :184.1 ## 57113943: 1 3rd Qu.:4 (5) (5) Poor : 55 3rd Qu.:211.0 ## 57117542: 1 Max. :4 Max. :525.0 ## (Other) :5108 NA&#39;s :79 ## a_hgt_ft a_hgt_in ## Min. :4.000 Min. : 0.000 ## 1st Qu.:5.000 1st Qu.: 2.000 ## Median :5.000 Median : 5.000 ## Mean :5.172 Mean : 5.386 ## 3rd Qu.:5.000 3rd Qu.: 8.000 ## Max. :6.000 Max. :11.000 ## NA&#39;s :6 NA&#39;s :10 bmiwgt5 &lt;- wave05 %&gt;% select(AID, wave, &quot;a_srh&quot; = H5ID1, &quot;a_wgt_lbs&quot; = H5ID3, &quot;a_hgt_ft&quot; = H5ID2F, &quot;a_hgt_in&quot; = H5ID2I) summary(bmiwgt5) ## AID wave a_srh a_wgt_lbs a_hgt_ft ## 57101310: 1 Min. :5 Min. :1.000 Min. :100.0 Min. : 4.000 ## 57111071: 1 1st Qu.:5 1st Qu.:2.000 1st Qu.:155.0 1st Qu.: 5.000 ## 57111786: 1 Median :5 Median :2.000 Median :185.0 Median : 5.000 ## 57113943: 1 Mean :5 Mean :2.473 Mean :192.2 Mean : 5.379 ## 57117997: 1 3rd Qu.:5 3rd Qu.:3.000 3rd Qu.:220.0 3rd Qu.: 5.000 ## 57118381: 1 Max. :5 Max. :5.000 Max. :400.0 Max. :98.000 ## (Other) :4190 NA&#39;s :4 NA&#39;s :25 NA&#39;s :2 ## a_hgt_in ## Min. : 0.0 ## 1st Qu.: 3.0 ## Median : 5.0 ## Mean : 10.6 ## 3rd Qu.: 8.0 ## Max. :998.0 ## NA&#39;s :6 typeof(bmiwgt5$a_hgt_ft) ## [1] &quot;double&quot; The “Rbind” function requires all datasets have a same numbers of columns. “setDT” and “fill=TRUE” are the functions from a “data.table” package that override this requirement. Now, we have created a long-form dataset (i.e., vars) from five sets of cross-sectional datasets. vars01 &lt;- rbind(setDT(bmiwgt1), setDT(bmiwgt2), setDT(bmiwgt3), setDT(bmiwgt4), setDT(bmiwgt5), fill=TRUE) vars &lt;- vars01[order(vars01$AID, vars01$wave), ] # 6504, 4834, 4882, 5114, 4196, 25530 6.7 Demographic variables - time-invariant demo_TI &lt;- wave01 %&gt;% select(AID, &quot;a_sex&quot; = BIO_SEX) 6.8 Merging datasets The following code merges a long-form dataset (i.e., vars) and a time-invariant dataset (i.e., demo_TI). Final01 &lt;- merge(vars, demo_TI, by = c(&quot;AID&quot;)) summary(Final01) ## AID wave a_srh a_wgt_lbs ## 57101310: 5 Min. :1.00 (2) (2) Very good:8494 Min. : 18.0 ## 57111071: 5 1st Qu.:1.00 (1) (1) Excellent:5861 1st Qu.:130.0 ## 57113943: 5 Median :3.00 (3) (3) Good :5522 Median :155.0 ## 57118381: 5 Mean :2.83 2 :1503 Mean :164.3 ## 57118943: 5 3rd Qu.:4.00 3 :1393 3rd Qu.:190.0 ## 57121404: 5 Max. :5.00 (Other) :2743 Max. :525.0 ## (Other) :25500 NA&#39;s : 14 NA&#39;s :457 ## a_hgt_ft a_hgt_in ## (5) (5) 5 feet:13438 (06) (6) 6 inches: 1664 ## 5 : 7504 (04) (4) 4 inches: 1624 ## (6) (6) 6 feet: 2128 (03) (3) 3 inches: 1451 ## 6 : 1664 (02) (2) 2 inches: 1432 ## (4) (4) 4 feet: 386 (07) (7) 7 inches: 1430 ## (Other) : 135 (Other) :17632 ## NA&#39;s : 275 NA&#39;s : 297 ## a_weightimage a_poorappetite ## (1) (1) Very underweight : 184 (0) (0) Never/rarely : 4192 ## (2) (2) Slightly underweight : 1632 (0) (0) Never : 2312 ## (3) (3) About the right weight: 5957 (1) (1) Just a few times : 1834 ## (4) (4) Slightly overweight : 3146 (1) (1) Sometimes : 1744 ## (5) (5) Very overweight : 400 (2) (2) About once a week: 508 ## NA&#39;s :14211 (Other) : 729 ## NA&#39;s :14211 ## a_sex ## (1) (1) Male :11874 ## (2) (2) Female:13654 ## NA&#39;s : 2 ## ## ## ## 6.9 Data management, recoding, and so on 6.9.1 BMI Alright, the following code does not work…. Final01$a_wgt_flag &lt;- ifelse(Final01$a_wgt_lbs &lt; 50, 1, 0) Final01$a_wgt_flag &lt;- ifelse(430 &lt; Final01$a_wgt_lbs, 1, 0) Final01$a_hgt_flag &lt;- ifelse(as.integer(Final01$a_hgt_ft) &lt; 4, 1, 0) Final01$a_hgt_flag &lt;- ifelse(95 &lt; as.integer(Final01$a_hgt_ft), 1, 0) Final01$a_hgt_flag &lt;- ifelse(95 &lt; as.integer(Final01$a_hgt_in), 1, 0) summary(Final01) ## AID wave a_srh a_wgt_lbs ## 57101310: 5 Min. :1.00 (2) (2) Very good:8494 Min. : 18.0 ## 57111071: 5 1st Qu.:1.00 (1) (1) Excellent:5861 1st Qu.:130.0 ## 57113943: 5 Median :3.00 (3) (3) Good :5522 Median :155.0 ## 57118381: 5 Mean :2.83 2 :1503 Mean :164.3 ## 57118943: 5 3rd Qu.:4.00 3 :1393 3rd Qu.:190.0 ## 57121404: 5 Max. :5.00 (Other) :2743 Max. :525.0 ## (Other) :25500 NA&#39;s : 14 NA&#39;s :457 ## a_hgt_ft a_hgt_in ## (5) (5) 5 feet:13438 (06) (6) 6 inches: 1664 ## 5 : 7504 (04) (4) 4 inches: 1624 ## (6) (6) 6 feet: 2128 (03) (3) 3 inches: 1451 ## 6 : 1664 (02) (2) 2 inches: 1432 ## (4) (4) 4 feet: 386 (07) (7) 7 inches: 1430 ## (Other) : 135 (Other) :17632 ## NA&#39;s : 275 NA&#39;s : 297 ## a_weightimage a_poorappetite ## (1) (1) Very underweight : 184 (0) (0) Never/rarely : 4192 ## (2) (2) Slightly underweight : 1632 (0) (0) Never : 2312 ## (3) (3) About the right weight: 5957 (1) (1) Just a few times : 1834 ## (4) (4) Slightly overweight : 3146 (1) (1) Sometimes : 1744 ## (5) (5) Very overweight : 400 (2) (2) About once a week: 508 ## NA&#39;s :14211 (Other) : 729 ## NA&#39;s :14211 ## a_sex a_wgt_flag a_hgt_flag ## (1) (1) Male :11874 Min. :0e+00 Min. :0 ## (2) (2) Female:13654 1st Qu.:0e+00 1st Qu.:0 ## NA&#39;s : 2 Median :0e+00 Median :0 ## Mean :2e-04 Mean :0 ## 3rd Qu.:0e+00 3rd Qu.:0 ## Max. :1e+00 Max. :0 ## NA&#39;s :457 NA&#39;s :297 6.9.2 Sampling weights 6.9.3 Multiple imputation 6.10 Analytic approach The following models are demonstration only - mostly, the models themselves do not make sense. 6.10.1 A linear regression with the current dataset lmer(a_wgt_lbs ~ as.numeric(a_srh) + a_sex + (1 | AID), data=Final01) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: a_wgt_lbs ~ as.numeric(a_srh) + a_sex + (1 | AID) ## Data: Final01 ## REML criterion at convergence: 248599 ## Random effects: ## Groups Name Std.Dev. ## AID (Intercept) 33.69 ## Residual 26.88 ## Number of obs: 25069, groups: AID, 6492 ## Fixed Effects: ## (Intercept) as.numeric(a_srh) a_sex(2) (2) Female ## 160.802 5.422 -25.999 "]]
